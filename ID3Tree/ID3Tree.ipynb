{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be roughly the content of the first code cell\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement ID3 decision-tree inference algorithm from scratch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#read election_clean.csv\n",
    "df1 = pd.read_csv(\"elections_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>education</th>\n",
       "      <th>religion</th>\n",
       "      <th>ethnic_male</th>\n",
       "      <th>ethnic_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sioux County</td>\n",
       "      <td>NE</td>\n",
       "      <td>Educated</td>\n",
       "      <td>CHRISTIAN GENERIC</td>\n",
       "      <td>MULTI MALE RATE</td>\n",
       "      <td>NATIVE AMERICAN FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Baltimore city</td>\n",
       "      <td>MD</td>\n",
       "      <td>Educated</td>\n",
       "      <td>OTHER MISC</td>\n",
       "      <td>WHITE MALE RATE</td>\n",
       "      <td>WHITE FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Chittenden County</td>\n",
       "      <td>VT</td>\n",
       "      <td>Educated</td>\n",
       "      <td>MAINLINE CHRISTIAN</td>\n",
       "      <td>ASIAN MALE RATE</td>\n",
       "      <td>BLACK FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Prince of Wales-Hyder Census Area</td>\n",
       "      <td>AK</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>OTHER MISC</td>\n",
       "      <td>BLACK MALE RATE</td>\n",
       "      <td>BLACK FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>St. Johns County</td>\n",
       "      <td>FL</td>\n",
       "      <td>Educated</td>\n",
       "      <td>MAINLINE CHRISTIAN</td>\n",
       "      <td>BLACK MALE RATE</td>\n",
       "      <td>BLACK FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>0</td>\n",
       "      <td>Clinton County</td>\n",
       "      <td>MO</td>\n",
       "      <td>Educated</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MULTI MALE RATE</td>\n",
       "      <td>BLACK FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>0</td>\n",
       "      <td>Union County</td>\n",
       "      <td>AR</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>MAINLINE CHRISTIAN</td>\n",
       "      <td>BLACK MALE RATE</td>\n",
       "      <td>BLACK FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>0</td>\n",
       "      <td>Garfield County</td>\n",
       "      <td>NE</td>\n",
       "      <td>Educated</td>\n",
       "      <td>MAINLINE CHRISTIAN</td>\n",
       "      <td>MULTI MALE RATE</td>\n",
       "      <td>BLACK FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>0</td>\n",
       "      <td>Greene County</td>\n",
       "      <td>IN</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>MAINLINE CHRISTIAN</td>\n",
       "      <td>MULTI MALE RATE</td>\n",
       "      <td>NATIVE AMERICAN FEMALE RATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>0</td>\n",
       "      <td>Morton County</td>\n",
       "      <td>ND</td>\n",
       "      <td>Educated</td>\n",
       "      <td>MAINLINE CHRISTIAN</td>\n",
       "      <td>NATIVE AMERICAN MALE RATE</td>\n",
       "      <td>NATIVE AMERICAN FEMALE RATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3145 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      democrat                             county state   education  \\\n",
       "0            0                       Sioux County    NE    Educated   \n",
       "1            1                     Baltimore city    MD    Educated   \n",
       "2            1                  Chittenden County    VT    Educated   \n",
       "3            0  Prince of Wales-Hyder Census Area    AK  Uneducated   \n",
       "4            0                   St. Johns County    FL    Educated   \n",
       "...        ...                                ...   ...         ...   \n",
       "3140         0                     Clinton County    MO    Educated   \n",
       "3141         0                       Union County    AR  Uneducated   \n",
       "3142         0                    Garfield County    NE    Educated   \n",
       "3143         0                      Greene County    IN  Uneducated   \n",
       "3144         0                      Morton County    ND    Educated   \n",
       "\n",
       "                religion                ethnic_male  \\\n",
       "0      CHRISTIAN GENERIC            MULTI MALE RATE   \n",
       "1             OTHER MISC            WHITE MALE RATE   \n",
       "2     MAINLINE CHRISTIAN            ASIAN MALE RATE   \n",
       "3             OTHER MISC            BLACK MALE RATE   \n",
       "4     MAINLINE CHRISTIAN            BLACK MALE RATE   \n",
       "...                  ...                        ...   \n",
       "3140            CATHOLIC            MULTI MALE RATE   \n",
       "3141  MAINLINE CHRISTIAN            BLACK MALE RATE   \n",
       "3142  MAINLINE CHRISTIAN            MULTI MALE RATE   \n",
       "3143  MAINLINE CHRISTIAN            MULTI MALE RATE   \n",
       "3144  MAINLINE CHRISTIAN  NATIVE AMERICAN MALE RATE   \n",
       "\n",
       "                    ethnic_female  \n",
       "0     NATIVE AMERICAN FEMALE RATE  \n",
       "1               WHITE FEMALE RATE  \n",
       "2               BLACK FEMALE RATE  \n",
       "3               BLACK FEMALE RATE  \n",
       "4               BLACK FEMALE RATE  \n",
       "...                           ...  \n",
       "3140            BLACK FEMALE RATE  \n",
       "3141            BLACK FEMALE RATE  \n",
       "3142            BLACK FEMALE RATE  \n",
       "3143  NATIVE AMERICAN FEMALE RATE  \n",
       "3144  NATIVE AMERICAN FEMALE RATE  \n",
       "\n",
       "[3145 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select categorical features from dataframe\n",
    "df = df1[['democrat', 'county', 'state', 'education', 'religion', 'ethnic_male','ethnic_female']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    When I ran my prediction function, the program reported an error.\n",
    "    I found out after testing that it was because some samples had missing values. \n",
    "    So I use dropna() here to remove the samples with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/3879422107.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#cleanning the data\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    My prediction function often fails to predict the results. \n",
    "    The reason for this is that given the large number of non-repeating attributes in the COUNT columns, \n",
    "    there are a large number of attributes in the TRAIN and TEST samples that are not present in each other.\n",
    "\n",
    "    When the COUNTY columns are removed, the accuracy increases from 25% to 88%. \n",
    "    \n",
    "    !!!   Uncomments the code in the code area below to test the results.   !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/483174569.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=['county'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['county'], axis = 1, inplace = True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    REPORT OF MAX TREE DEPTH:\n",
    "    For the above reason max tree depth is 2 because only two attributes, COUNTY and STATE, \n",
    "    are needed to divide the target values, but when these two features are removed the maximum depth of the tree increases to 4.\n",
    "    Obviously the latter is more reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    REPORT OF THE NUMBER OF THE REPEATED:\n",
    "    Because I have fixed the maximum depth to the number of features-1 when I designed the decision tree \n",
    "    (because the depth of the decision tree is 0 at the beginning), \n",
    "    there is no possibility of the same feature appearing at different depths, \n",
    "    given that the depth control has been implemented. So I think the REPEATED feature of the decision tree I built is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Classes are created below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self, TreeNode):\n",
    "        self.root = TreeNode\n",
    "    \n",
    "    \n",
    "class Edge():\n",
    "    def __init__(self, df, name, value):\n",
    "        self.df = df\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "    \n",
    "    def add_child(self, TreeNode):\n",
    "        self.children.append(TreeNode)\n",
    "    \n",
    "\n",
    "class TreeNode():\n",
    "    def __init__(self, df, name, depth, max_depth):\n",
    "        self.df = df\n",
    "        self.children = []\n",
    "        self.edges = []\n",
    "        self.name = name\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "\n",
    "    def add_child(self, TreeNode):\n",
    "        self.children.append(TreeNode)\n",
    "    \n",
    "    def add_edge(self, edge):\n",
    "        self.edges.append(edge)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __repr__(self, level=0):\n",
    "        ret = \"\\t\"*level+repr(self.name)+\"\\n\"\n",
    "        for child in self.children:\n",
    "            ret += child.__repr__(level+1)\n",
    "        return ret\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new treeNode\n",
    "def makeTreeNode(df, feature, depth, max_depth):\n",
    "    return TreeNode(df, feature, depth, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new subframe\n",
    "def get_sub_frame(df, feature, variable):\n",
    "    sub_frame = df[df[feature] == variable].reset_index(drop = True)\n",
    "    return sub_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meke new edge\n",
    "def makeEdge(Node,feature, variable):\n",
    "    sub_frame = get_sub_frame(Node.df, feature, variable)\n",
    "    values = sub_frame['target'].unique()\n",
    "    if len(values) <= 1:\n",
    "        value = values[0]\n",
    "    else:\n",
    "        value = None\n",
    "    edge = Edge(sub_frame, variable, value)\n",
    "    return edge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Gini "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\operatorname{Gini}(Y)=-\\sum_{i=1}^{k}\\left(P_{i}\\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: dataframe\n",
    "# Funtion: calculate the Gini impurity of the dataframe\n",
    "# Output: None\n",
    "# Return: float --- Gini impurity of the frame\n",
    "def getTotalGini(df):\n",
    "    target_values_count = df['target'].value_counts()\n",
    "    num_sample = len(df)\n",
    "    Gini = 0\n",
    "    for i in target_values_count:\n",
    "        Gini += (i/num_sample)**2\n",
    "    return 1 - Gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: dataframe & string---name of a feature\n",
    "# Funtion: find the Gini impurity of the feature\n",
    "# Output: None\n",
    "# Return: float --- Gini impurity of the feature\n",
    "def getSplitGini(df, feature):\n",
    "    variables = df[feature].value_counts().keys().tolist()\n",
    "    counts = df[feature].value_counts().tolist()\n",
    "    total_num_sample = len(df)\n",
    "    total_Gini = 0\n",
    "    for i in range(len(variables)):\n",
    "        sub_frame = get_sub_frame(df, feature, variables[i])\n",
    "        sub_frame.dropna(inplace = True)\n",
    "        variable_percentage = len(sub_frame)/total_num_sample\n",
    "        target_values_count = sub_frame['target'].value_counts()\n",
    "        num_sample = counts[i]\n",
    "        part_Gini = 0\n",
    "        for j in target_values_count:\n",
    "            part_Gini += (j/num_sample)**2\n",
    "        total_Gini += variable_percentage * part_Gini\n",
    "    return 1 - total_Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: TreeNode object\n",
    "# Funtion: find the feature with the best information gain\n",
    "# Output: None\n",
    "# Return: string---name of the best feature\n",
    "def find_largest_IG_Gini(Node):\n",
    "    features = Node.df.keys()[:-1]\n",
    "    IG_list = []\n",
    "    for feature in features:\n",
    "        information_gain = getTotalGini(Node.df) - getSplitGini(Node.df, feature)\n",
    "        IG_list.append(information_gain)\n",
    "    IG_list = np.array(IG_list)\n",
    "    index_return = IG_list.argmax()\n",
    "    return features[index_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: TreeNode object\n",
    "# Funtion: build the decision tree recursively\n",
    "# Output: None\n",
    "# Return: TreeNode---root of the tree\n",
    "def decisionTreeGini(treeNode):\n",
    "    best_feature = find_largest_IG_Gini(treeNode)\n",
    "    variables = treeNode.df[best_feature].unique()\n",
    "    treeNode.name = best_feature\n",
    "    for variable in variables:\n",
    "        edge = makeEdge(treeNode, best_feature,variable)\n",
    "        treeNode.add_edge(edge)\n",
    "        if edge.value != None:\n",
    "            pass\n",
    "        elif treeNode.depth == treeNode.max_depth:\n",
    "            vars = edge.df['target'].value_counts().keys().tolist()\n",
    "            counts = edge.df['target'].value_counts().tolist()\n",
    "            counts = np.array(counts)\n",
    "            edge.value = vars[np.argmax(counts)]\n",
    "        else:\n",
    "            new_tree_node = makeTreeNode(edge.df, None, treeNode.depth+1, treeNode.max_depth)\n",
    "            treeNode.add_child(new_tree_node)\n",
    "            edge.add_child(new_tree_node)\n",
    "            decisionTreeGini(new_tree_node)\n",
    "    return treeNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H(Y)=-\\sum_{j=1}^{k} P_{j} \\log P_{j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: dataframe & string---name of a feature\n",
    "# Funtion: find the entropy of the feature\n",
    "# Output: None\n",
    "# Return: float --- entropy of the feature\n",
    "def getSplitEntropy(df, feature):\n",
    "    variables = df[feature].value_counts().keys().tolist()\n",
    "    counts = df[feature].value_counts().tolist()\n",
    "    total_num_sample = len(df)\n",
    "    total_entropy = 0\n",
    "    for i in range(len(variables)):\n",
    "        sub_frame = get_sub_frame(df, feature, variables[i])\n",
    "        #sub_frame.dropna(inplace = True)\n",
    "        variable_percentage = len(sub_frame)/total_num_sample\n",
    "        target_values_count = sub_frame['target'].value_counts()\n",
    "        num_sample = counts[i]\n",
    "        part_entropy = 0\n",
    "        for j in target_values_count:\n",
    "            part_entropy += - (j/num_sample) * np.log2(j/num_sample)\n",
    "        total_entropy += variable_percentage * part_entropy\n",
    "    return total_entropy\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: dataframe\n",
    "# Funtion: calculate the entropy of the dataframe\n",
    "# Output: None\n",
    "# Return: float --- entropy of the frame\n",
    "def getTotalEntropy(df):\n",
    "    target_values_count = df['target'].value_counts()\n",
    "    num_sample = len(df)\n",
    "    entropy = 0\n",
    "    for i in target_values_count:\n",
    "        entropy += - (i/num_sample) * np.log2(i/num_sample)\n",
    "    return float(entropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: TreeNode object\n",
    "# Funtion: find the feature with the best information gain\n",
    "# Output: None\n",
    "# Return: string---name of the best feature\n",
    "def find_largest_IG(Node):\n",
    "    features = Node.df.keys()[:-1]\n",
    "    IG_list = []\n",
    "    for feature in features:\n",
    "        information_gain = getTotalEntropy(Node.df) - getSplitEntropy(Node.df, feature)\n",
    "        IG_list.append(information_gain)\n",
    "    IG_list = np.array(IG_list)\n",
    "    index_return = IG_list.argmax()\n",
    "    return features[index_return]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: TreeNode object\n",
    "# Funtion: build the decision tree recursively\n",
    "# Output: None\n",
    "# Return: TreeNode---root of the tree\n",
    "def decisionTree(treeNode):\n",
    "    best_feature = find_largest_IG(treeNode)\n",
    "    variables = treeNode.df[best_feature].unique()\n",
    "    treeNode.name = best_feature\n",
    "    for variable in variables:\n",
    "        edge = makeEdge(treeNode, best_feature,variable)\n",
    "        treeNode.add_edge(edge)\n",
    "        if edge.value != None:\n",
    "            pass\n",
    "        elif treeNode.depth == treeNode.max_depth:\n",
    "            vars = edge.df['target'].value_counts().keys().tolist()\n",
    "            counts = edge.df['target'].value_counts().tolist()\n",
    "            counts = np.array(counts)\n",
    "            edge.value = vars[np.argmax(counts)]\n",
    "        else:\n",
    "            #print(\"edge.df =\", edge.df.head())\n",
    "            new_tree_node = makeTreeNode(edge.df, None, treeNode.depth+1, treeNode.max_depth)\n",
    "            treeNode.add_child(new_tree_node)\n",
    "            edge.add_child(new_tree_node)\n",
    "            decisionTree(new_tree_node)\n",
    "    return treeNode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: TreeNode object & Dataframe---a row of dataframe\n",
    "# Funtion: recursively predict the target value \n",
    "# Output: None\n",
    "# Return: int---target value\n",
    "def predictions(treeNode, sample):\n",
    "    node_name = treeNode.name\n",
    "    attitude = sample[node_name].values[0]\n",
    "    #print('attitude = ', attitude)\n",
    "    branch_val = None\n",
    "    branch = None\n",
    "    for i in treeNode.edges:\n",
    "        if i.name == attitude:\n",
    "            branch_val = i.value\n",
    "            branch = i\n",
    "            if branch_val != None:\n",
    "                return branch_val\n",
    "            else:\n",
    "                branch_val = predictions(i.children[0], sample)\n",
    "    return branch_val\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/1605402897.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['target'] = df[target]\n",
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/1605402897.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop([target], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Put the target coloum to the last column of df\n",
    "target = 'democrat'\n",
    "\n",
    "df['target'] = df[target]\n",
    "df.drop([target], axis = 1, inplace = True)\n",
    "\n",
    "#split trainning and testing samples\n",
    "df_train = df.sample(frac=0.7, random_state=1)\n",
    "df_test=df.drop(df_train.index)\n",
    "\n",
    "# Create Tree\n",
    "max_depth = len(df.keys())-2\n",
    "root = TreeNode(df_train, None,0,max_depth)\n",
    "root2 = TreeNode(df_train, None,0,max_depth)\n",
    "tree = Tree(root)\n",
    "\n",
    "Tree = decisionTree(root)\n",
    "#print(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree2 = decisionTreeGini(root2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training entropy tree = 93.18%\n",
      "accuracy of testing entropy tree = 85.35%\n"
     ]
    }
   ],
   "source": [
    "target_val = np.array(df_train['target'])\n",
    "total_num = len(target_val)\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    sample = df_train[i:i+1]    \n",
    "    predict_val = predictions(root, sample)\n",
    "    if target_val[i] == predict_val:\n",
    "        count += 1\n",
    "print('accuracy of training entropy tree = {:.2%}'.format(count/total_num))\n",
    "\n",
    "target_val = np.array(df_test['target'])\n",
    "total_num = len(target_val)\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    sample = df_test[i:i+1]    \n",
    "    predict_val = predictions(root, sample)\n",
    "    if target_val[i] == predict_val:\n",
    "        count += 1\n",
    "print('accuracy of testing entropy tree = {:.2%}'.format(count/total_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The following is the prediction from the tree generated by the Gini function. \n",
    "    It can be seen that the accuracy of the tree generated by the Gini function is 26%, \n",
    "    which is slightly higher than that of the tree generated by the entropy function, \n",
    "    before removing the COUNTY and STATE features. \n",
    "    However, after removing the COUNTY and STATE features, the accuracies are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training Gini tree = 93.18%\n",
      "accuracy of testing Gini tree = 84.93%\n"
     ]
    }
   ],
   "source": [
    "target_val = np.array(df_train['target'])\n",
    "total_num = len(target_val)\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    sample = df_train[i:i+1]    \n",
    "    predict_val = predictions(root2, sample)\n",
    "    if target_val[i] == predict_val:\n",
    "        count += 1\n",
    "print('accuracy of training Gini tree = {:.2%}'.format(count/total_num))\n",
    "\n",
    "target_val = np.array(df_test['target'])\n",
    "total_num = len(target_val)\n",
    "count = 0\n",
    "\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    sample = df_test[i:i+1]    \n",
    "    predict_val = predictions(root2, sample)\n",
    "    #predict_val = 0\n",
    "    #if predict_val == None:\n",
    "    #    predict_val = 0\n",
    "    if target_val[i] == predict_val:\n",
    "        count += 1\n",
    "print('accuracy of testing Gini tree = {:.2%}'.format(count/total_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    By summarizing the age-related features, accuracy improved by 0.7% in the test with COUNTY and STATE removed. \n",
    "    But no improvement was seen in the unprocessed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the age-related features\n",
    "df1['age'] = df1.apply((lambda x: 0 if x['age_young'] > x['age_adult'] and x['age_young'] > x['age_old'] \n",
    "else (1 if x['age_adult'] > x['age_old'] and x['age_adult'] > x['age_old'] else 2)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select categorical features from dataframe\n",
    "df2 = df1[['democrat', 'county', 'state', 'education', 'religion', 'ethnic_male','ethnic_female','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/4208084113.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.drop(columns=['county', 'state'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#drop COUNTY and STATE to increase the accuracy\n",
    "df2.drop(columns=['county', 'state'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/1018254845.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.dropna(inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#cleanning the data\n",
    "df2.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/1747619249.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['target'] = df2[target]\n",
      "/var/folders/dz/ffb7x_vj5vl9758_4vqfvj3m0000gn/T/ipykernel_78707/1747619249.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.drop([target], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Put the target coloum to the last column of df\n",
    "target = 'democrat'\n",
    "\n",
    "df2['target'] = df2[target]\n",
    "df2.drop([target], axis = 1, inplace = True)\n",
    "\n",
    "#split trainning and testing samples\n",
    "df_train2 = df2.sample(frac=0.7, random_state=1)\n",
    "df_test2=df2.drop(df_train.index)\n",
    "\n",
    "# Create Tree\n",
    "max_depth = len(df2.keys())-2\n",
    "root3 = TreeNode(df_train2, None,0,max_depth)\n",
    "#root2 = TreeNode(df_train, None,0,max_depth)\n",
    "#tree = Tree(root3)\n",
    "\n",
    "Tree = decisionTree(root3)\n",
    "#Tree.levelOrder(root3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training entropy tree= 89.96%\n",
      "accuracy of testing entropy tree= 87.96%\n"
     ]
    }
   ],
   "source": [
    "target_val = np.array(df_train2['target'])\n",
    "total_num = len(target_val)\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df_train2)):\n",
    "    sample = df_train2[i:i+1]\n",
    "    #print('target value = ', target_val[i])\n",
    "    predict_val = predictions(root3, sample)\n",
    "    if target_val[i] == predict_val:\n",
    "        count += 1\n",
    "print('accuracy of training entropy tree= {:.2%}'.format(count/total_num))\n",
    "\n",
    "target_val = np.array(df_test2['target'])\n",
    "total_num = len(target_val)\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df_test2)):\n",
    "    sample = df_test2[i:i+1]\n",
    "    #print('target value = ', target_val[i])\n",
    "    predict_val = predictions(root3, sample)\n",
    "    if target_val[i] == predict_val:\n",
    "        count += 1\n",
    "print('accuracy of testing entropy tree= {:.2%}'.format(count/total_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources that helped me:   \n",
    "\n",
    "https://www.youtube.com/watch?v=YG_nOa6-6Q8   \n",
    "\n",
    "https://stackoverflow.com/questions/20242479/printing-a-tree-data-structure-in-python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('my-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fffe89ac52413fb39337687d7244f9d047e73cfd698b292667d72b398446bc8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
